{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "testloader= torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "classes=('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is on CUDA\n",
      "[Epoch :: 1, Mini Batch ::  2000] loss: 2.199\n",
      "[Epoch :: 1, Mini Batch ::  4000] loss: 1.874\n",
      "[Epoch :: 1, Mini Batch ::  6000] loss: 1.728\n",
      "[Epoch :: 1, Mini Batch ::  8000] loss: 1.607\n",
      "[Epoch :: 1, Mini Batch :: 10000] loss: 1.540\n",
      "[Epoch :: 1, Mini Batch :: 12000] loss: 1.497\n",
      "[Epoch :: 2, Mini Batch ::  2000] loss: 1.445\n",
      "[Epoch :: 2, Mini Batch ::  4000] loss: 1.392\n",
      "[Epoch :: 2, Mini Batch ::  6000] loss: 1.380\n",
      "[Epoch :: 2, Mini Batch ::  8000] loss: 1.362\n",
      "[Epoch :: 2, Mini Batch :: 10000] loss: 1.328\n",
      "[Epoch :: 2, Mini Batch :: 12000] loss: 1.307\n",
      "[Epoch :: 3, Mini Batch ::  2000] loss: 1.239\n",
      "[Epoch :: 3, Mini Batch ::  4000] loss: 1.221\n",
      "[Epoch :: 3, Mini Batch ::  6000] loss: 1.221\n",
      "[Epoch :: 3, Mini Batch ::  8000] loss: 1.237\n",
      "[Epoch :: 3, Mini Batch :: 10000] loss: 1.193\n",
      "[Epoch :: 3, Mini Batch :: 12000] loss: 1.200\n",
      "[Epoch :: 4, Mini Batch ::  2000] loss: 1.118\n",
      "[Epoch :: 4, Mini Batch ::  4000] loss: 1.103\n",
      "[Epoch :: 4, Mini Batch ::  6000] loss: 1.115\n",
      "[Epoch :: 4, Mini Batch ::  8000] loss: 1.117\n",
      "[Epoch :: 4, Mini Batch :: 10000] loss: 1.112\n",
      "[Epoch :: 4, Mini Batch :: 12000] loss: 1.116\n",
      "[Epoch :: 5, Mini Batch ::  2000] loss: 1.026\n",
      "[Epoch :: 5, Mini Batch ::  4000] loss: 1.055\n",
      "[Epoch :: 5, Mini Batch ::  6000] loss: 1.061\n",
      "[Epoch :: 5, Mini Batch ::  8000] loss: 1.029\n",
      "[Epoch :: 5, Mini Batch :: 10000] loss: 1.030\n",
      "[Epoch :: 5, Mini Batch :: 12000] loss: 1.032\n",
      "[Epoch :: 6, Mini Batch ::  2000] loss: 0.957\n",
      "[Epoch :: 6, Mini Batch ::  4000] loss: 0.972\n",
      "[Epoch :: 6, Mini Batch ::  6000] loss: 0.972\n",
      "[Epoch :: 6, Mini Batch ::  8000] loss: 0.992\n",
      "[Epoch :: 6, Mini Batch :: 10000] loss: 0.991\n",
      "[Epoch :: 6, Mini Batch :: 12000] loss: 0.994\n",
      "[Epoch :: 7, Mini Batch ::  2000] loss: 0.902\n",
      "[Epoch :: 7, Mini Batch ::  4000] loss: 0.915\n",
      "[Epoch :: 7, Mini Batch ::  6000] loss: 0.941\n",
      "[Epoch :: 7, Mini Batch ::  8000] loss: 0.918\n",
      "[Epoch :: 7, Mini Batch :: 10000] loss: 0.952\n",
      "[Epoch :: 7, Mini Batch :: 12000] loss: 0.924\n",
      "[Epoch :: 8, Mini Batch ::  2000] loss: 0.845\n",
      "[Epoch :: 8, Mini Batch ::  4000] loss: 0.891\n",
      "[Epoch :: 8, Mini Batch ::  6000] loss: 0.884\n",
      "[Epoch :: 8, Mini Batch ::  8000] loss: 0.904\n",
      "[Epoch :: 8, Mini Batch :: 10000] loss: 0.919\n",
      "[Epoch :: 8, Mini Batch :: 12000] loss: 0.920\n",
      "[Epoch :: 9, Mini Batch ::  2000] loss: 0.822\n",
      "[Epoch :: 9, Mini Batch ::  4000] loss: 0.826\n",
      "[Epoch :: 9, Mini Batch ::  6000] loss: 0.850\n",
      "[Epoch :: 9, Mini Batch ::  8000] loss: 0.872\n",
      "[Epoch :: 9, Mini Batch :: 10000] loss: 0.875\n",
      "[Epoch :: 9, Mini Batch :: 12000] loss: 0.880\n",
      "[Epoch :: 10, Mini Batch ::  2000] loss: 0.772\n",
      "[Epoch :: 10, Mini Batch ::  4000] loss: 0.810\n",
      "[Epoch :: 10, Mini Batch ::  6000] loss: 0.820\n",
      "[Epoch :: 10, Mini Batch ::  8000] loss: 0.824\n",
      "[Epoch :: 10, Mini Batch :: 10000] loss: 0.871\n",
      "[Epoch :: 10, Mini Batch :: 12000] loss: 0.856\n",
      "[Epoch :: 11, Mini Batch ::  2000] loss: 0.736\n",
      "[Epoch :: 11, Mini Batch ::  4000] loss: 0.779\n",
      "[Epoch :: 11, Mini Batch ::  6000] loss: 0.787\n",
      "[Epoch :: 11, Mini Batch ::  8000] loss: 0.821\n",
      "[Epoch :: 11, Mini Batch :: 10000] loss: 0.817\n",
      "[Epoch :: 11, Mini Batch :: 12000] loss: 0.825\n",
      "[Epoch :: 12, Mini Batch ::  2000] loss: 0.706\n",
      "[Epoch :: 12, Mini Batch ::  4000] loss: 0.749\n",
      "[Epoch :: 12, Mini Batch ::  6000] loss: 0.771\n",
      "[Epoch :: 12, Mini Batch ::  8000] loss: 0.786\n",
      "[Epoch :: 12, Mini Batch :: 10000] loss: 0.810\n",
      "[Epoch :: 12, Mini Batch :: 12000] loss: 0.823\n",
      "[Epoch :: 13, Mini Batch ::  2000] loss: 0.682\n",
      "[Epoch :: 13, Mini Batch ::  4000] loss: 0.716\n",
      "[Epoch :: 13, Mini Batch ::  6000] loss: 0.753\n",
      "[Epoch :: 13, Mini Batch ::  8000] loss: 0.752\n",
      "[Epoch :: 13, Mini Batch :: 10000] loss: 0.791\n",
      "[Epoch :: 13, Mini Batch :: 12000] loss: 0.777\n",
      "[Epoch :: 14, Mini Batch ::  2000] loss: 0.690\n",
      "[Epoch :: 14, Mini Batch ::  4000] loss: 0.706\n",
      "[Epoch :: 14, Mini Batch ::  6000] loss: 0.728\n",
      "[Epoch :: 14, Mini Batch ::  8000] loss: 0.728\n",
      "[Epoch :: 14, Mini Batch :: 10000] loss: 0.750\n",
      "[Epoch :: 14, Mini Batch :: 12000] loss: 0.772\n",
      "[Epoch :: 15, Mini Batch ::  2000] loss: 0.661\n",
      "[Epoch :: 15, Mini Batch ::  4000] loss: 0.690\n",
      "[Epoch :: 15, Mini Batch ::  6000] loss: 0.717\n",
      "[Epoch :: 15, Mini Batch ::  8000] loss: 0.722\n",
      "[Epoch :: 15, Mini Batch :: 10000] loss: 0.744\n",
      "[Epoch :: 15, Mini Batch :: 12000] loss: 0.762\n",
      "[Epoch :: 16, Mini Batch ::  2000] loss: 0.641\n",
      "[Epoch :: 16, Mini Batch ::  4000] loss: 0.679\n",
      "[Epoch :: 16, Mini Batch ::  6000] loss: 0.705\n",
      "[Epoch :: 16, Mini Batch ::  8000] loss: 0.715\n",
      "[Epoch :: 16, Mini Batch :: 10000] loss: 0.735\n",
      "[Epoch :: 16, Mini Batch :: 12000] loss: 0.735\n",
      "[Epoch :: 17, Mini Batch ::  2000] loss: 0.617\n",
      "[Epoch :: 17, Mini Batch ::  4000] loss: 0.667\n",
      "[Epoch :: 17, Mini Batch ::  6000] loss: 0.686\n",
      "[Epoch :: 17, Mini Batch ::  8000] loss: 0.694\n",
      "[Epoch :: 17, Mini Batch :: 10000] loss: 0.739\n",
      "[Epoch :: 17, Mini Batch :: 12000] loss: 0.724\n",
      "[Epoch :: 18, Mini Batch ::  2000] loss: 0.600\n",
      "[Epoch :: 18, Mini Batch ::  4000] loss: 0.637\n",
      "[Epoch :: 18, Mini Batch ::  6000] loss: 0.669\n",
      "[Epoch :: 18, Mini Batch ::  8000] loss: 0.701\n",
      "[Epoch :: 18, Mini Batch :: 10000] loss: 0.700\n",
      "[Epoch :: 18, Mini Batch :: 12000] loss: 0.737\n",
      "[Epoch :: 19, Mini Batch ::  2000] loss: 0.611\n",
      "[Epoch :: 19, Mini Batch ::  4000] loss: 0.655\n",
      "[Epoch :: 19, Mini Batch ::  6000] loss: 0.651\n",
      "[Epoch :: 19, Mini Batch ::  8000] loss: 0.655\n",
      "[Epoch :: 19, Mini Batch :: 10000] loss: 0.694\n",
      "[Epoch :: 19, Mini Batch :: 12000] loss: 0.712\n",
      "[Epoch :: 20, Mini Batch ::  2000] loss: 0.585\n",
      "[Epoch :: 20, Mini Batch ::  4000] loss: 0.598\n",
      "[Epoch :: 20, Mini Batch ::  6000] loss: 0.638\n",
      "[Epoch :: 20, Mini Batch ::  8000] loss: 0.677\n",
      "[Epoch :: 20, Mini Batch :: 10000] loss: 0.690\n",
      "[Epoch :: 20, Mini Batch :: 12000] loss: 0.709\n",
      "[Epoch :: 21, Mini Batch ::  2000] loss: 0.604\n",
      "[Epoch :: 21, Mini Batch ::  4000] loss: 0.581\n",
      "[Epoch :: 21, Mini Batch ::  6000] loss: 0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-44:\n",
      "Process Process-43:\n",
      "  File \"/usr/local/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/siplab/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/siplab/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/local/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/local/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-17adc5296b66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Loop over all the mini-batches therea are 12500 mini batches of size 4 each !\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m# get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrebuild_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mhmac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHALLENGE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message = %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model on CUDA\n",
    "net = LeNet().cuda()\n",
    "\n",
    "lossvsiter_mom=[]\n",
    "\n",
    "\n",
    "# To see if the model is on CUDA or not !\n",
    "if (next(net.parameters()).is_cuda) :\n",
    "    print(\"The model is on CUDA\")\n",
    "else :\n",
    "    print(\"The model is on CPU\")\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Declare a loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Declare an optimizer\n",
    "optimizer = optim.SGD(net.parameters(),lr=0.001,momentum=0.9)\n",
    "\n",
    "\n",
    "# No of iterations !\n",
    "iterations = 25\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "    \n",
    "    # Reset the loss for the current epoch !\n",
    "    running_loss = 0.0\n",
    "    tloss = 0.0\n",
    "    # Loop over all the mini-batches therea are 12500 mini batches of size 4 each !\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # wrap them in Variable & if possible make them cuda tensors\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "        # zero the parameter gradients for the current epoch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        \n",
    "        # forward\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients of whatever variable set to req_gardients = True\n",
    "        loss.backward()\n",
    "        \n",
    "        # Take one step of the gradient descent for this epoch ! \n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        tloss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[Epoch :: %d, Mini Batch :: %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            lossvsiter_mom.append(running_loss / 2000)\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    loss_list.append(tloss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 61 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    images=images.cuda()\n",
    "    labels=labels.cuda()\n",
    "    try:\n",
    "        outputs = net(Variable(images))\n",
    "    except RuntimeError as re:\n",
    "        print(outputs.is_cuda)\n",
    "        print(str(re))\n",
    "        sys.exit()\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "Accuracy of the network on the 50000 trained images: 80 %\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(trainloader, 0):\n",
    "    images, labels = data\n",
    "    images=images.cuda()\n",
    "    labels=labels.cuda()\n",
    "    try:\n",
    "        outputs = net(Variable(images))\n",
    "    except RuntimeError as re:\n",
    "        print(outputs.is_cuda)\n",
    "        print(str(re))\n",
    "        sys.exit()\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    if (i%1000) == 0:\n",
    "        print(i)\n",
    "\n",
    "print('Accuracy of the network on the 50000 trained images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 60 %\n",
      "Accuracy of   car : 77 %\n",
      "Accuracy of  bird : 61 %\n",
      "Accuracy of   cat : 47 %\n",
      "Accuracy of  deer : 62 %\n",
      "Accuracy of   dog : 57 %\n",
      "Accuracy of  frog : 84 %\n",
      "Accuracy of horse : 74 %\n",
      "Accuracy of  ship : 85 %\n",
      "Accuracy of truck : 78 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    images=images.cuda()\n",
    "    labels=labels.cuda()\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f67d8e3d4a8>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCgcRETnO/weqxqwAzLoL1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f682432c908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
