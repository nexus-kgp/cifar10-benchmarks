{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets keep the architecture same as Architecture 2 , there we got 65% accuracy on test and 75% accuracy on train set\n",
    "\n",
    "Goals :: Introduce Weight Decay and study the accuracy for different values sampled over a log scale\n",
    "### Regularization with 1e-5 didnt help much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "testloader= torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "classes=('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 6 Layers : 3 conv layers and 3 fully connected layers !\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 5,padding=2)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5,padding=2)\n",
    "        self.fc1 = nn.Linear(32*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 32 *4* 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is on CUDA\n",
      "[Epoch :: 1, Mini Batch ::  2000] loss: 1.912\n",
      "[Epoch :: 1, Mini Batch ::  4000] loss: 1.613\n",
      "[Epoch :: 1, Mini Batch ::  6000] loss: 1.473\n",
      "[Epoch :: 1, Mini Batch ::  8000] loss: 1.416\n",
      "[Epoch :: 1, Mini Batch :: 10000] loss: 1.375\n",
      "[Epoch :: 1, Mini Batch :: 12000] loss: 1.336\n",
      "[Epoch :: 2, Mini Batch ::  2000] loss: 1.229\n",
      "[Epoch :: 2, Mini Batch ::  4000] loss: 1.206\n",
      "[Epoch :: 2, Mini Batch ::  6000] loss: 1.206\n",
      "[Epoch :: 2, Mini Batch ::  8000] loss: 1.199\n",
      "[Epoch :: 2, Mini Batch :: 10000] loss: 1.162\n",
      "[Epoch :: 2, Mini Batch :: 12000] loss: 1.165\n",
      "[Epoch :: 3, Mini Batch ::  2000] loss: 1.108\n",
      "[Epoch :: 3, Mini Batch ::  4000] loss: 1.072\n",
      "[Epoch :: 3, Mini Batch ::  6000] loss: 1.091\n",
      "[Epoch :: 3, Mini Batch ::  8000] loss: 1.068\n",
      "[Epoch :: 3, Mini Batch :: 10000] loss: 1.077\n",
      "[Epoch :: 3, Mini Batch :: 12000] loss: 1.080\n",
      "[Epoch :: 4, Mini Batch ::  2000] loss: 0.992\n",
      "[Epoch :: 4, Mini Batch ::  4000] loss: 0.999\n",
      "[Epoch :: 4, Mini Batch ::  6000] loss: 1.006\n",
      "[Epoch :: 4, Mini Batch ::  8000] loss: 1.035\n",
      "[Epoch :: 4, Mini Batch :: 10000] loss: 1.041\n",
      "[Epoch :: 4, Mini Batch :: 12000] loss: 1.034\n",
      "[Epoch :: 5, Mini Batch ::  2000] loss: 0.933\n",
      "[Epoch :: 5, Mini Batch ::  4000] loss: 0.945\n",
      "[Epoch :: 5, Mini Batch ::  6000] loss: 0.958\n",
      "[Epoch :: 5, Mini Batch ::  8000] loss: 0.974\n",
      "[Epoch :: 5, Mini Batch :: 10000] loss: 0.995\n",
      "[Epoch :: 5, Mini Batch :: 12000] loss: 0.973\n",
      "[Epoch :: 6, Mini Batch ::  2000] loss: 0.867\n",
      "[Epoch :: 6, Mini Batch ::  4000] loss: 0.912\n",
      "[Epoch :: 6, Mini Batch ::  6000] loss: 0.934\n",
      "[Epoch :: 6, Mini Batch ::  8000] loss: 0.928\n",
      "[Epoch :: 6, Mini Batch :: 10000] loss: 0.934\n",
      "[Epoch :: 6, Mini Batch :: 12000] loss: 0.942\n",
      "[Epoch :: 7, Mini Batch ::  2000] loss: 0.839\n",
      "[Epoch :: 7, Mini Batch ::  4000] loss: 0.867\n",
      "[Epoch :: 7, Mini Batch ::  6000] loss: 0.888\n",
      "[Epoch :: 7, Mini Batch ::  8000] loss: 0.912\n",
      "[Epoch :: 7, Mini Batch :: 10000] loss: 0.881\n",
      "[Epoch :: 7, Mini Batch :: 12000] loss: 0.915\n",
      "[Epoch :: 8, Mini Batch ::  2000] loss: 0.807\n",
      "[Epoch :: 8, Mini Batch ::  4000] loss: 0.827\n",
      "[Epoch :: 8, Mini Batch ::  6000] loss: 0.839\n",
      "[Epoch :: 8, Mini Batch ::  8000] loss: 0.853\n",
      "[Epoch :: 8, Mini Batch :: 10000] loss: 0.883\n",
      "[Epoch :: 8, Mini Batch :: 12000] loss: 0.880\n",
      "[Epoch :: 9, Mini Batch ::  2000] loss: 0.776\n",
      "[Epoch :: 9, Mini Batch ::  4000] loss: 0.801\n",
      "[Epoch :: 9, Mini Batch ::  6000] loss: 0.839\n",
      "[Epoch :: 9, Mini Batch ::  8000] loss: 0.844\n",
      "[Epoch :: 9, Mini Batch :: 10000] loss: 0.836\n",
      "[Epoch :: 9, Mini Batch :: 12000] loss: 0.865\n",
      "[Epoch :: 10, Mini Batch ::  2000] loss: 0.778\n",
      "[Epoch :: 10, Mini Batch ::  4000] loss: 0.810\n",
      "[Epoch :: 10, Mini Batch ::  6000] loss: 0.776\n",
      "[Epoch :: 10, Mini Batch ::  8000] loss: 0.819\n",
      "[Epoch :: 10, Mini Batch :: 10000] loss: 0.818\n",
      "[Epoch :: 10, Mini Batch :: 12000] loss: 0.810\n",
      "[Epoch :: 11, Mini Batch ::  2000] loss: 0.750\n",
      "[Epoch :: 11, Mini Batch ::  4000] loss: 0.749\n",
      "[Epoch :: 11, Mini Batch ::  6000] loss: 0.780\n",
      "[Epoch :: 11, Mini Batch ::  8000] loss: 0.790\n",
      "[Epoch :: 11, Mini Batch :: 10000] loss: 0.810\n",
      "[Epoch :: 11, Mini Batch :: 12000] loss: 0.806\n",
      "[Epoch :: 12, Mini Batch ::  2000] loss: 0.725\n",
      "[Epoch :: 12, Mini Batch ::  4000] loss: 0.726\n",
      "[Epoch :: 12, Mini Batch ::  6000] loss: 0.758\n",
      "[Epoch :: 12, Mini Batch ::  8000] loss: 0.771\n",
      "[Epoch :: 12, Mini Batch :: 10000] loss: 0.792\n",
      "[Epoch :: 12, Mini Batch :: 12000] loss: 0.806\n",
      "[Epoch :: 13, Mini Batch ::  2000] loss: 0.703\n",
      "[Epoch :: 13, Mini Batch ::  4000] loss: 0.721\n",
      "[Epoch :: 13, Mini Batch ::  6000] loss: 0.737\n",
      "[Epoch :: 13, Mini Batch ::  8000] loss: 0.745\n",
      "[Epoch :: 13, Mini Batch :: 10000] loss: 0.766\n",
      "[Epoch :: 13, Mini Batch :: 12000] loss: 0.767\n",
      "[Epoch :: 14, Mini Batch ::  2000] loss: 0.683\n",
      "[Epoch :: 14, Mini Batch ::  4000] loss: 0.711\n",
      "[Epoch :: 14, Mini Batch ::  6000] loss: 0.721\n",
      "[Epoch :: 14, Mini Batch ::  8000] loss: 0.737\n",
      "[Epoch :: 14, Mini Batch :: 10000] loss: 0.756\n",
      "[Epoch :: 14, Mini Batch :: 12000] loss: 0.745\n",
      "[Epoch :: 15, Mini Batch ::  2000] loss: 0.658\n",
      "[Epoch :: 15, Mini Batch ::  4000] loss: 0.689\n",
      "[Epoch :: 15, Mini Batch ::  6000] loss: 0.695\n",
      "[Epoch :: 15, Mini Batch ::  8000] loss: 0.732\n",
      "[Epoch :: 15, Mini Batch :: 10000] loss: 0.728\n",
      "[Epoch :: 15, Mini Batch :: 12000] loss: 0.731\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model on CUDA\n",
    "net = Net().cuda()\n",
    "\n",
    "# net=Net()\n",
    "\n",
    "lossvsiter=[]\n",
    "\n",
    "# To see if the model is on CUDA or not !\n",
    "if (next(net.parameters()).is_cuda) :\n",
    "    print(\"The model is on CUDA\")\n",
    "else :\n",
    "    print(\"The model is on CPU\")\n",
    "\n",
    "# Import the optimizers \n",
    "import torch.optim as optim\n",
    "\n",
    "# Declare a loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Declare an optimizer\n",
    "optimizer = optim.Adam(net.parameters(),weight_decay=1e-5)\n",
    "\n",
    "#No of iterations !\n",
    "iterations = 15\n",
    "\n",
    "\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "    \n",
    "    # Reset the loss for the current epoch !\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Loop over all the mini-batches therea are 12500 mini batches of size 4 each !\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # wrap them in Variable & if possible make them cuda tensors\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "        # zero the parameter gradients for the current epoch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        \n",
    "        # forward\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients of whatever variable set to req_gardients = True\n",
    "        loss.backward()\n",
    "        \n",
    "        # Take one step of the gradient descent for this epoch ! \n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[Epoch :: %d, Mini Batch :: %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            lossvsiter.append(running_loss / 2000)\n",
    "            running_loss = 0.0\n",
    "        \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"PyTorch-Architecture-2-with-reg.pkl\",\"wb\") as f:\n",
    "    pickle.dump(lossvsiter,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 64 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    images=images.cuda()\n",
    "    labels=labels.cuda()\n",
    "    try:\n",
    "        outputs = net(Variable(images))\n",
    "    except RuntimeError as re:\n",
    "        print(outputs.is_cuda)\n",
    "        print(str(re))\n",
    "        sys.exit()\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "Accuracy of the network on the 50000 trained images: 74 %\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(trainloader, 0):\n",
    "    images, labels = data\n",
    "    images=images.cuda()\n",
    "    labels=labels.cuda()\n",
    "    try:\n",
    "        outputs = net(Variable(images))\n",
    "    except RuntimeError as re:\n",
    "        print(outputs.is_cuda)\n",
    "        print(str(re))\n",
    "        sys.exit()\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    if (i%1000) == 0:\n",
    "        print(i)\n",
    "\n",
    "print('Accuracy of the network on the 50000 trained images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44431"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 76 %\n",
      "Accuracy of   car : 88 %\n",
      "Accuracy of  bird : 57 %\n",
      "Accuracy of   cat : 46 %\n",
      "Accuracy of  deer : 57 %\n",
      "Accuracy of   dog : 46 %\n",
      "Accuracy of  frog : 64 %\n",
      "Accuracy of horse : 70 %\n",
      "Accuracy of  ship : 76 %\n",
      "Accuracy of truck : 60 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    images=images.cuda()\n",
    "    labels=labels.cuda()\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9121172297298907,\n",
       " 1.6129605130255222,\n",
       " 1.4729537923783065,\n",
       " 1.416227998584509,\n",
       " 1.375367299631238,\n",
       " 1.3362291313260795,\n",
       " 1.2292245556712151,\n",
       " 1.2056728691607714,\n",
       " 1.2056791387498378,\n",
       " 1.1985564230382442,\n",
       " 1.16192292791605,\n",
       " 1.164634777367115,\n",
       " 1.107630993247032,\n",
       " 1.0718171118497848,\n",
       " 1.0913361265659332,\n",
       " 1.0682286374121905,\n",
       " 1.0765112414211035,\n",
       " 1.0802829616889358,\n",
       " 0.9918590277731418,\n",
       " 0.9985699627324939,\n",
       " 1.0057257095724343,\n",
       " 1.0352969634756446,\n",
       " 1.0412683415338397,\n",
       " 1.0340903357714415,\n",
       " 0.9326629136800766,\n",
       " 0.9448711917363107,\n",
       " 0.9578155973255634,\n",
       " 0.9737446712702513,\n",
       " 0.995305515371263,\n",
       " 0.9731355479322373,\n",
       " 0.8667125270105899,\n",
       " 0.9121933790966869,\n",
       " 0.9335940982848406,\n",
       " 0.9277727754376829,\n",
       " 0.9338530479259789,\n",
       " 0.9420998954158276,\n",
       " 0.8389087582714856,\n",
       " 0.8672108516469598,\n",
       " 0.8884238287657499,\n",
       " 0.9122314798012375,\n",
       " 0.8810214663296938,\n",
       " 0.9146589816119521,\n",
       " 0.8068617780730128,\n",
       " 0.8266580955078825,\n",
       " 0.8390151681266725,\n",
       " 0.8527508663097396,\n",
       " 0.8825953815784305,\n",
       " 0.8799839144395665,\n",
       " 0.7757914870297536,\n",
       " 0.8006056750118733,\n",
       " 0.8390912830736488,\n",
       " 0.8438117331769317,\n",
       " 0.836480291094631,\n",
       " 0.8647782570710406,\n",
       " 0.778098555399105,\n",
       " 0.8102009810237214,\n",
       " 0.7755457388143987,\n",
       " 0.8190933798444457,\n",
       " 0.8180201661493629,\n",
       " 0.8098428883291781,\n",
       " 0.7502977394815534,\n",
       " 0.7491449759891257,\n",
       " 0.7797945690029301,\n",
       " 0.7901002900488675,\n",
       " 0.8102624038336799,\n",
       " 0.8060694569488988,\n",
       " 0.7252223771559074,\n",
       " 0.7262538097011857,\n",
       " 0.7580531028029509,\n",
       " 0.7712212788960896,\n",
       " 0.7915108684627339,\n",
       " 0.8060830308552831,\n",
       " 0.7028937427460914,\n",
       " 0.7212157436949201,\n",
       " 0.7370015752532054,\n",
       " 0.7452063578872475,\n",
       " 0.7662860164460726,\n",
       " 0.7673069787863642,\n",
       " 0.6832362397785764,\n",
       " 0.71056703462312,\n",
       " 0.7211904178354889,\n",
       " 0.736674323845189,\n",
       " 0.7563110939213075,\n",
       " 0.7449963719584047,\n",
       " 0.6579850652874447,\n",
       " 0.6890402573710307,\n",
       " 0.6948827538569458,\n",
       " 0.7315730545748956,\n",
       " 0.7283340704753064,\n",
       " 0.7314211289258674]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossvsiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4XNW1xuHfUu9dbpKLLFew5SYXTDM1poQSeoc4cYAQ\nEkhIgCTkpt5AEkIK5dICBEKvIQZTQjNuuMi9YFkucpVkS7Zsq+/7x4yEZKuMZI1H1nzv8/hBM3Pm\nzJphrM/n7H3WNuccIiIiACGBLkBERLoOhYKIiDRQKIiISAOFgoiINFAoiIhIA4WCiIg0UCiIiEgD\nhYKIiDRQKIiISIOwQBfQXmlpaW7AgAGBLkNE5KiycOHCYudcelvbHXWhMGDAABYsWBDoMkREjipm\nttGX7XT6SEREGigURESkgUJBREQaKBRERKSBQkFERBooFEREpIFCQUREGgRNKKzZvpc/zlzD7n1V\ngS5FRKTLCppQKCjex98/WsfWsgOBLkVEpMsKmlBIigkHoHR/dYArERHpuoImFJJjIgDYvV+nj0RE\nWhJEoaAjBRGRtgRNKCQ2hIKOFEREWhI0oRAZFkpMRKiOFEREWhE0oQCQFB3OboWCiEiLgisUYiIo\nO6DTRyIiLQmyUNCRgohIa4IqFJJjIjTQLCLSiqAKhaSYcA00i4i0IvhC4UA1zrlAlyIi0iUFVSgk\nx0RQW+fYW1kT6FJERLqkoAqFxGjvBWz7dApJRKQ5fgsFM3vSzHaa2fIWHk80s3+b2RIzW2FmN/ir\nlnr1/Y9KNS1VRKRZ/jxSeAqY2srj3wVWOudGAVOAP5lZhB/raeiUqmmpIiLN81soOOc+BXa1tgkQ\nb2YGxHm39evJ/qT6IwVNSxURaVZYAF/778BbwFYgHrjMOVfnzxdUp1QRkdYFcqD5a0Ae0AcYDfzd\nzBKa29DMppvZAjNbUFRU1OEXbBhoViiIiDQrkKFwA/Ca81gHFADDmtvQOfeocy7XOZebnp7e4RcM\nCw0hPipMC+2IiLQgkKGwCTgNwMx6AkOB9f5+0aSYcMoO6EhBRKQ5fhtTMLPn8cwqSjOzQuAXQDiA\nc+4R4NfAU2a2DDDgJ865Yn/VUy85JkJHCiIiLfBbKDjnrmjj8a3Amf56/ZYkak0FEZEWBdUVzeA5\nUijTkYKISLOCLhS0poKISMuCMBQi2FNRTW2dOqWKiBws6EIhOSYc52CPZiCJiBwi6EKhvv9RqUJB\nROQQQRgKnv5HmpYqInKo4AsFb6uLMg02i4gcIuhCIVlHCiIiLQq6UEhSp1QRkRYFXSgkRIUTYlpT\nQUSkOUEXCiEhplYXIiItCLpQAM8MJE1JFRE5VJCGQrhOH4mINCM4QyE6XAPNIiLNCMpQ0JoKIiLN\nC8pQSIwJ18VrIiLNCMpQSI6JYG9lDdW1dYEuRUSkSwnSUPC2utAMJBGRJoIyFBK9rS40A0lEpKmg\nDIX6IwVdwCYi0lRQhkJSdP2RgkJBRKSx4AyFhiMFnT4SEWksqENB01JFRJryWyiY2ZNmttPMlrey\nzRQzyzOzFWb2ib9qOVhcZBhhIaYjBRGRg/jzSOEpYGpLD5pZEvAQcJ5z7ljgEj/WcvBrkxoXQdHe\nyiP1kiIiRwW/hYJz7lNgVyubXAm85pzb5N1+p79qac6A1FgKivcdyZcUEenyAjmmMARINrOPzWyh\nmV3b0oZmNt3MFpjZgqKiok558YHpceQXlXfKvkREuotAhkIYMA44B/ga8HMzG9Lchs65R51zuc65\n3PT09E558ez0WHbvr2bXPo0riIjUC2QoFAIznXP7nHPFwKfAqCP14tk94gBYr6MFEZEGgQyFN4ET\nzCzMzGKAicCqI/Xi2WmeUNApJBGRr4T5a8dm9jwwBUgzs0LgF0A4gHPuEefcKjN7F1gK1AGPO+da\nnL7a2TKSo4kIC2F9kQabRUTq+S0UnHNX+LDNH4A/+KuG1oSGGAPTYnWkICLSSFBe0VxvYHos+TpS\nEBFpENShkJ0ex6Zd+6mq0WI7IiKgUKC2zrFpl44WREQgyENhYHosAOt2KhRERCDoQ0HTUkVEGgvq\nUIiLDKNnQqSmpYqIeAV1KIBnXEFHCiIiHgoFbyg45wJdiohIwAV9KAxMj2VvRQ1F5VpbQUQk6EMh\nO72+MZ7GFUREFAo9NANJRKRe0IdC74QoosJDyNe1CiIiCoWQEGNgWhzri3WkICIS9KEAnlNIOn0k\nIqJQAGBIjzgKdx9g596KQJciIhJQCgXg7JzeOAevL9oS6FJERAJKoYBnWmpu/2ReWrBZF7GJSFBT\nKHhdkptJftE+Fm0qDXQpIiIBo1DwOienD9Hhoby8YHOgSxERCRiFgldcZBjn5PTm30u2sr+qJtDl\niIgEhEKhkUtz+7KvqpYZy7YHuhQRkYBQKDQyfkAyA1JjdApJRIKW30LBzJ40s51mtryN7cabWY2Z\nXeyvWnxlZlyS25d5BbvYUKy2FyISfPx5pPAUMLW1DcwsFLgXeM+PdbTLRWMzCQ0xnphVEOhSRESO\nOL+FgnPuU2BXG5t9D3gV2OmvOtqrV2IUl43vy/PzN7GpZH+gyxEROaICNqZgZhnAhcDDgaqhJd8/\nbTChIcb9768JdCkiIkdUIAeaHwB+4pyra2tDM5tuZgvMbEFRUZHfC+uZEMUNx2fx5pKtrNq2x++v\nJyLSVQQyFHKBF8xsA3Ax8JCZXdDchs65R51zuc653PT09CNS3E0nZxMfGcYfZ+poQUSCR8BCwTmX\n5Zwb4JwbALwC3OyceyNQ9RwsMSacG6dk8+HqnXyxoa2hERGR7sGfU1KfB+YAQ82s0MymmdmNZnaj\nv16zs90wOYse8ZHc+85qNcoTkaAQ5q8dO+euaMe21/urjsMRHRHKD04fwt2vL2Pmih1MHdEr0CWJ\niPiVrmhuw6W5mQzqEcfv31lFVU2bY+IiIkc1hUIbwkJDuPvsYWwo2c+/5m0MdDkiIn6lUPDBKUN7\nMDk7lb98+CVlB6oDXY6IiN8oFHxgZtx99nBKD1Tz0MfrAl2OiIjfKBR8NCIjkQvHZPCPzzewrexA\noMsREfELhUI73HhyNlU1dXy2tjjQpYiI+IVPoWBm3zezBPN4wswWmdmZ/i6uqxmUHkdcZBjLtpQF\nuhQREb/w9Ujhm865PcCZQDJwDfB7v1XVRYWEGCMyEliqUBCRbsrXUDDvf88G/umcW9HovqCSk5nE\nqm17dM2CiHRLvobCQjN7D08ozDSzeCAofyuOzEikqqaOtTv2BroUEZFO52soTAPuBMY75/YD4cAN\nfquqC8vJTATQuIKIdEu+hsJxwBrnXKmZXQ38DAjK34r9UmJIiApjaWFQvn0R6eZ8DYWHgf1mNgr4\nIZAPPOO3qrowMyMnM4llW0oDXYqISKfzNRRqnKd39PnA351zDwLx/iuraxuZmcia7XuprKkNdCki\nIp3K11DYa2Z34ZmK+h8zC8EzrhCURmYkUl3rWLNdg80i0r34GgqXAZV4rlfYDmQCf/BbVV3cyAzP\nYLPGFUSku/EpFLxB8ByQaGbnAhXOuaAcUwDITI4mOSacZQoFEelmfG1zcSkwH7gEuBSYZ2YX+7Ow\nrszMGJmZpCubRaTb8XU5zp/iuUZhJ4CZpQMfAK/4q7CuLicjkYc/yaeiupao8NBAlyMi0il8HVMI\nqQ8Er5J2PLdbGpmZSG2dY+W2PYEuRUSk0/j6i/1dM5tpZteb2fXAf4AZ/iur66u/snm5TiGJSDfi\n60DzHcCjQI73z6POuZ/4s7CurldCFGlxkXy8pgjPJRwiIkc/n08BOededc7d7v3zuj+LOhqYGddP\n7s9/V+/kvplrAl2OiEinaHWg2cz2As39M9gA55xLaOW5TwLnAjudcyOaefwq4Cfefe0FbnLOLWlH\n7QH33VMGsa2sgoc/zic5JpzpJ2UHuiQRkcPSaig45w6nlcVTwN9puUdSAXCyc263mZ2F5/TUxMN4\nvSPOzPjV+SMoPVDN72asJio8lMnZqfWP0jclmsgwzUwSkaOHr1NS280596mZDWjl8dmNbs7Fc5X0\nUSc0xPjzpaPZc6Cae95c0eSx+Kgwzhjek6kjenHSkHRNXRWRLs9vodBO04B3WnrQzKYD0wH69et3\npGryWURYCI9dm8sna4saVmSrqatjTn4J763cwWuLt9A/NYb/3HoicZFd5SMXETmU+XPmjPdI4e3m\nxhQabXMK8BBwgnOupK195ubmugULFnRajf5WXVvHzBXbueVfi/nOyQO566zhgS5JRIKQmS10zuW2\ntV1AL0AzsxzgceB8XwLhaBQeGsK5OX24ZFwmT84qIL+oPNAliYi0KGChYGb9gNeAa5xzawNVx5Hy\n46nDiAoL5Zf/XqnrGkSky/JbKJjZ88AcYKiZFZrZNDO70cxu9G5yD5AKPGRmeWZ29JwT6oD0+Ehu\nO2MIn64t4v2VOwJdjohIs/w6puAPR9uYQmPVtXWc89fP2F9Vy62nDaZw9wEKd+8nt38KV07segPo\nItJ9+DqmoFA4wmbnF3PlY/MACDGIDg+lzsEXPztdM5NExG98DQX9FjrCJmen8cHtJxEZFkqvxCiW\nFpZx0cOz+c/SrVw2XkcLIhJYQd3+OlAG9Yinb0oM4aEhjO2XRHZ6LC8vKAx0WSIiCoVAMzMuye3L\ngo27NV1VRAJOodAFfGNMBqEhxisLdbQgIoGlUOgCeiREMWVIOq8uLKSmti7Q5YhIEFModBGX5Gay\nc28ln31ZHOhSRCSIKRS6iFOH9SQlNoKXF24OdCkiEsQUCl1ERFgIF4zO4P2VOygurwx0OSISpBQK\nXchVk/rhHPzhXS3vKSKBoVDoQrLT4/jmCVm8uGAzCzfubvKYc459lTUBqkxEgoVCoYv5/mmD6ZUQ\nxc/fWN4wE6miupabn1vE2F+/z+x8DUSLiP8oFLqY2Mgwfn7uMazctodn526k7EA11z45n3eWbyc5\nJoJvP72AvM2lzT53b0U1Czfu4u2lW6nW1FYR6QA1xOuCnHNc++R88jaV0icpmvXF5fzp0tFMzErh\n4kdms7eihhenH8eQnnEs3LiblxZs5vN1JWwpPdCwjz9fNooLxxyVy16LiB+oS+pRbn1ROVMf+IyI\nsBD+75pxHD8oDYBNJfu55P9mU1sHCVFhrC/eR2xEKFOG9eCY3gkM7RnP7S/lcdaI3tx7cU6A34WI\ndBXqknqUG5gex7++PZGU2AgGpsc13N8vNYZnp03k2ifnkxYXyU1Tsjl7ZG9iG7XdnpCVwryCbrm6\nqYj4mUKhC8sdkNLs/YN7xjPnrtNafN7ErFQ+WLWTHXsq6JkQ5a/yRKQb0kBzNzQhyxMm8wp2BbgS\nETnaKBS6oWP7JBAXGca89R07hVRdW8eKrWW6LkIkCOn0UTcUFhrCuP7J7TpSKK+s4Y3FW/h0bRFz\n8kvYW1lDZFgIU4amc/bI3pw+vGeTcQsR6Z70t7ybmjgwhfveXUNxeSVpcZGtbltX5/jOPxfw+boS\nMpKiOXdUH3L7J7O0sJR3lm9n5oodHD8olee+NekIVS8igaJQ6KYmZqUC8EXBLs4a2bvVbR/+JJ/P\n15Xw2wtHcOWEfpgZABeNy+QXXz+WX729kmfmbGB/VQ0xEfrKiHRnfhtTMLMnzWynmS1v4XEzs7+a\n2TozW2pmY/1VSzAamZFIdHhom6eQFm7cxf3vr+Xro/o0CYR6ISHGiYPTqHOwrLDMnyWLSBfgz4Hm\np4CprTx+FjDY+2c68LAfawk6EWEhjO2fxNxWBpvL9ldz6/N59EmK4rcXjjgkEOqN6psEwJLC5ttr\niEj34bdQcM59CrT2z9TzgWecx1wgycxaP88h7TIxK5U1O/ZSur+qyf01tXXMzi/mpucWsmNPBX+7\nYiwJUeEt7ictLpLM5OgWey6JSPcRyBPEGUDjZcYKvfdtC0w53c/ErBScgy827OakIWnMXb+LmSu2\nM3P5dkr2VREVHsL/nHcso71HAq0Z3TeJRQe18xaR7ueoGDU0s+l4TjHRr1+/AFdz9BjVN4mIsBB+\n85+VlLxYRXllDTERoZwyrAfnjOzNlKHpPg8cj+6bxNtLt7FzTwU92nmVdG2d46evL2PRpt3844YJ\nZCRFd+TtiMgREMhQ2AL0bXQ703vfIZxzjwKPgqchnv9L6x6iwkM5Y3hP5hXs4tyc3px5bE8mZ6cR\nFR7a7n2N6ec5msjbXMqZx/by+Xm1dY4fvpTHG3lbiQgL4crH5vLi9OPolaj2GyJdUSBD4S3gFjN7\nAZgIlDnndOqokz141Viccy0OIvvq2D6JhIVYu0KhpraOH768hDfztnLH14YyaWAq1z4xjysfm8sL\n35lEj3gFg0hX488pqc8Dc4ChZlZoZtPM7EYzu9G7yQxgPbAOeAy42V+1BLvDDQTwHHUM6x3v82Dz\ngapafvBiHm/mbeXHU4fy3VMGMa5/Mk99cwLb91Rw1WPzKNtffdh1iUjn8tuRgnPuijYed8B3/fX6\n0vlG903ijcVbqa1zhIa0HDRrtu/lln8tYl1ROXefPYzpJ2U3PDZ+QAqPXpPL1U/M462lW7lmUv8j\nUbqI+EgN8cRno/smU15Zw/qi8mYfd87x3LyNnPf3WezeX80z35zQJBDqHT8olZTYCJbpugeRLueo\nmH0kXUP91NXFm0sZ3DO+yWPri8r5xVsr+OzLYk4cnMb9l44mPb75nktmxsiMRJbqCmmRLkdHCuKz\ngWmxxEeFNRlX2F9Vw73vruZrD3xK3qZS/ufrx/D0DRNaDIR6OZmJfLmznANVtf4uW0TaQUcK4rOQ\nEGNUZhJ5m0qpq3O8vngLf5i5hu17KrhobCZ3njWszTCoNzIjkdo6x8ptZYzr3/wKc74qKa/kzbyt\nJMeGc+GYzMPal0iwUyhIu4zum8TDn+Rz3oOzWL5lD6MyE3nwqjHt/sVe309paWHrobC9rILq2jr6\npsQ0uX9/VQ2zvizmtUVb+HD1DqprHXGRYZw/KoOQVgbBRaR1CgVpl3EDkqn9yLGrvIq/XD6ar+f0\n6dAv4Z4JUfSIj2y18+rHa3Yy/Z8Lqaqpo19KDCcMTiMzOZrZ60qYX7CLqto6UmMjuO64AURHhPK3\n/65jfXE5g3rEt7hPEWmdQkHaZcqQdJ6dNpFx/ZOJjmj/ldGN5WQmsnRL86Hw0eqdfOefCxnUI45L\ncjP5fF0xb+VtpbyyhiE947hucn9OGpLOpIGphIeGsG7nXv7233XkbS5TKIgcBoWCtIuZccLgtE7Z\n18iMJD5cvZPyyhriGi31+eGqHdz07CKG9Irj2WkTSYqJ4Ibjs6iurWPPgWpSm1lJbmBaHHGRYSzZ\nXMrF4zpnXGH19j1kp8cRHqr5GBI89G2XgMnJTMQ5WN7oaCFvcyk3PruQ4b3jeW7aJJJiIhoeCw8N\naTYQwDMInpOZ2K41H3btq+LKx+by7NyNhzz239U7mPrAZ7y+qNl2XCLdlkJBAmZkZiLQdEW3Bz5Y\nS3xUOM9Mm0hiTMtrPDRnVN8kVm3bQ0V129Nc91XW8M2nvmB2fgm//PcKVmz9qoa9FdX89HXPgoGL\nNqlduAQXhYIETFpcJBlJ0Q3jCsu3lPHxmiKmnZBFYnT7AgFgVGYi1bWOVdv2tLpdVU0dNz23iKWF\npdx3UQ7JMRHc9mJeQ5jc965nmm3flGiWtTDmIdJdKRQkoEZmJDa0u3j443ziI8O4uoP9kBqWDW2l\naV9dneOOV5bw6doi/vcbI7l0fF/uuziHtTvK+ePMNXyxYRf/nLuR6ycP4Os5fVizfa9PRx4i3YVC\nQQJqZGYiG0r2s3jTbmYs38a1k/t36CgBoJd3mmtL7TPq6hw/fWNZQyvvy8Z7FmyaMrQH10zqz+Oz\nCrjlX4vISIrmR2cOJSczkZo6x5rtezv8/nbsqSC/qFzBIkcNzT6SgMrxjiv88KUlRIaFcMPxWR3e\nl5kxqm8Sec0MNtfWOX7y6lJeWVjId0/J5uYpTRv13XX2MGatK6ageB/PfHMCsZFhjMjw1LZ0S1nD\nUUh75G0u5ZJHZlNd61kXKi0ugtOH9+T3F+V04N2JHBk6UpCAGun9xbu+eB+Xj+9HWguzi3w1um8S\n64v2UXbgq7UaamrruP2lPF5ZWMhtpw/hjq8NO2SNiZiIMJ6+YQKPXD2Wk4akA5CRFE1KbATLO9C4\nb29FNbc+v5ge8VH86ZJR/OjMIWSlxfLSgs3sq6w5rPco4k8KBQmopJgI+qfGEBZiTD9p4GHvL+eg\nGU3OOe54ZWnDKaPvnz64xef2S41h6ojeDbfNjBEZLV9g1xLnHD97YzlbSg/wl8tHc9G4TG45dTA3\nTcmm7qApuIfDOcd7K7azp0KLFUnnUShIwE0/aSB3njWMPknRh72vnAzvYLP3FNLTszfw+uIt3Hb6\nEL57yqAO7C+RL3e0b7D51UVbeDNvKz84bTC5A77q65ST+VW/p87w7NyNTP/nQp6ZvaFT9icCCgXp\nAq6a2J9vnXj4RwkAiTHhDEyLJW9zKYs27ea3M1Zx+vAefO/U9gcCwIgMz2BzW9Nc6y3fUsY9by5n\nYlYKNx8UQvVTcJsb82ivvM2l/OrtlQDMWV9y2PsTqadQkG5nVN8kFm3czS3PLaJXYhR/umR0hzun\n1p+OauuUT0V1Lfe+u5oLHvyc2MgwHrh8dLNLlo7qm8jSdobCnopqqmvrGm7v3lfFd59bRI/4KL4x\nJoOFG3dTWaPZTdI5NPtIup1RmYm8vngLEWEhvHbT5HZfGd1Y78QoUmMjWj3l89mXRfzsjeVsLNnP\nJeMyufvs4STHRjS7bU5mEjOWbWfXvipSWtimqqaOlxduZsGG3SzetJsNJftJjgln6ohenDOyD4/P\nWk/R3kpeuek4tpVV8NriLSwtLGP8gMNbl0IEFArSDU0cmIoZ/PK8YxumlXaUmTEyM7HZK5sLivfx\n2/+s4oNVOxiQGsO/vjWRyYNabxY4KvOrMY9ThvZodps/f7CWhz/OJz0+krH9krgkty9rd+zlrbyt\nPD9/MwC/uWAEOZlJ9Eupwgzm5pcoFKRTKBSk2xneO4G8e87s8EVwBxuZkchnXxZTUV1LVHgoB6pq\n+dN7a3h6zgYiQkP48dShfPP4LKLC224lPjIzETNYurms2VDYvGs/T8wq4MIxGdx/6agmU2crqmv5\neM1Odu+v5vLxfQHP7K1hvRKYW1DC92h5ZpWIrxQK0i11ViBA46VD95CdFse0p79g4abdXJbbl9vP\nHEKP+Cif9xUXGUZ2elyL4wr3vruaEIMfTx16yLUUUeGhTabM1ps0MIXn52+isqaWyLC2g6m2zrFi\naxkRYSHERoQRFxlGUkz4Ia8nwcmvoWBmU4G/AKHA48653x/0eD/gaSDJu82dzrkZ/qxJpL3qu7l+\nsHIHd61aRkHxPh68cixnjzz0F7QvRmUm8cnanTjnmvwiXrhxN28v3catpw2md6Lv03MnDUzlH59v\n8Hlc4ZFP8vnDzDVN7hvcI46Lx2Vy4ZgMeiT4HnLS/fgtFMwsFHgQOAMoBL4ws7eccysbbfYz4CXn\n3MNmdgwwAxjgr5pEOqJXQhRpcZE89HE+cZFhPHXD+DbHDlozqm8iry4qZGtZBRneazOcc/z67ZX0\niI/kO+28iG9iVsoh4wr14x0/PWc4WWmxDdvurajm0U/XMzk7lasn9ae8sobS/VXMXLGD/31nNfe+\nu5rLxvflf7/R8VYcry4s5Pn5m8hKi2VERiIjMhIY0ze509bOrqmtY391LQlRnXc0KF/x55HCBGCd\nc249gJm9AJwPNA4FByR4f04EtvqxHpEOMTOOy05l9rpinv7mhMMevG64iG1zaUMo/HvpNvI2l/KH\ni3OIjWzfX8uDxxXq23os3lTK3opqXpg+qeGI5OnZGyg7UM2dZw1rqANg+knZrC8q52//Xcfz8zdz\n3eQBDOuV0NJLtujRT/P53YzVDEyLpaB4Hy8vLATg5+cew7QTOt7Xqt7yLWX88KUllOyrZM5dp2lV\nPD/w5yeaAWxudLvQe19j/wNcbWaFeI4SvufHekQ67L6Lcvj8zlMPOxAAhveOJzzUGi5iKyjexy/e\nXM6xfRK4aGzHlhKdNDCl4XqFRz9bz+JNpZx5TE/mFeziFe8v5r0V1Tw+q4BTh/VoEgj1BqbH8bNz\nhhMWYu1ecc45x33vruZ3M1ZzTk5v3v3BSSz42enMves0stNj+Wj1zg69r3pVNXXc//5azn/wcwqK\n91FcXsXaHR3vXistC3TMXgE85ZzLBM4G/mlmh9RkZtPNbIGZLSgqKjriRYpER4T6NLvIF5FhoQzv\nncDSzWWUlFdy/T/mY2Y8eOXYDp9imTQwlYrqOl5eUMgD73/J1GN78cjV4xg/IJnfzlhFSXklz8zZ\nSOn+ar5/WsuzlFLjIpkyNJ038rZQW+d8eu2tpQe4/aUlPPRxPldM6MdfLx9DRFgIZkavxChOHtKD\n+Rt2dbh9eNHeSi56eDZ//fBLzh/Vh5dvPA6AJZu1AJI/+DMUtgB9G93O9N7X2DTgJQDn3BwgCjjk\nZK1z7lHnXK5zLjc9Pd1P5YocOTneax+mPb2A7WUVPH5dLgManftvr/pxhXveXE5cVBi/uXAEISHG\n7y4cyb7KGn7+5nIe+2w9pw7r0WYb8AvHZLJjTyVz8ltvn5FfVM4dLy/hpPs+4t9LtnLrqYP43YUj\nDrmS+8TBaVTV1LFgQ/uXNi3cvZ9L/28O63aW88jVY7n/stHkZCaSGB3e7ivDxTf+DIUvgMFmlmVm\nEcDlwFsHbbMJOA3AzIbjCQUdCki3NyozifLKGpYUlvKXy8cwtl/yYe0vKSaC4b0SqHPw2wtGNLQg\nH9wznu+clM2MZdvbPEqod9rwHsRHhfHa4sIWt5m5Yjtn3P8J/166lasn9eeTH5/C7WceOo0WYEJW\nCuGhxmfr2vdXe93Oci55ZA7F5ZU8+60JDdNxG9bNaGWFPek4vw00O+dqzOwWYCae6aZPOudWmNmv\ngAXOubeAHwKPmdlteAadr3fO+XbMKnIUm5iVSkRoCHefPYypI3p1yj5vPiWb9UX7OOugqbK3nDqI\n91ZuJzseZMCmAAAQ20lEQVQ9zqfFgqLCQzk3pzdv5m3lNxfUEBPR9NfE9rIKfvLqUkZkJPLk9ePb\nXAMjNjKMMf2SmfVlMZzl23v5dG0Rt72Yhxm8OP04junTdNB7dGYif/+oiP1Vh9bXXrV1jsqa2sPe\nT3fh10/Be83BjIPuu6fRzyuB4/1Zg0hX1C81hmW/PNOni818dW5On2bvjwoP5e3vndhsg76WXDgm\nk+fnb2bmiu1cOOarwe+6OscPX86jsrqOBy4b7fOiSCcOSuNP76+lpLyS1Faes63sAL9+eyUzlm1n\nYFosT1w/vsmU2nqj+iZ516bYw4Ss9rf3eH7+Jv78/lr2VFRTUe1pNvjrC0ZwTQfXB+9OAj3QLBK0\nOjMQ2hIRFtKuUMjtn0xmcjSvHTQL6cnPC/h8XQn3fP0YBqbH+by/EwZ7hgpntzJO8dIXmzntT5/w\n4aqd/OjMIbzzgxObDQT4alrvkg6cQnpyVgF3vbaMAamxXHfcAH5w+mAykqJ5b8X2du+rsZVb97Ct\n7MBh7aMr0PGSiBwiJMS4cEwGD360jlcXFpISF0FldS33vbuGM47p2dB7yVc5mUnER4Ux68tivj7q\n0COaJZtLuev1ZUzMSuHei3LomxLT6v7S4z1rUyxp52DzI5/k8/t3VjP12F789QrPLCmAsgPV7WoV\ncrCXvtjMXa8vI9SMKyf247unDCI9/vCWlg0UhYKINOuisZk88kk+P3x5ScN96fGR3HtRTrv7JIWG\nGJOzU5m1rviQ9h4V1bXc/lIePeIjefjqcT73rRrVN9HnUNhaeoDHPyvgyc8L+PqoPtx/6agmF75N\nzk7jH59vIG9TKRMHpvr8vpxzPPSxp23IiYPTyEiK5p9zN/LiF5v53mmDuHlKxxZ3CiSFgog0a0Ba\nLPPvPp3i8kr2VtZQXlHD8N4JLa4D0ZYTBqczc8UOCor3NTn19MeZa8gv2sez0ya2q5HhKO/aFC2N\nU9TWOf6zbBsvL9jsDSO4YkJffnPByENOpU3ISiHEPKe3fA2F2jpPa5KnZm/gwjEZ3HtRDhFhIXzn\n5Gz+560V3PfuGi4YndEpy8weSQoFEWlRcmxEiwsGtdeJ3n5Rn68rbgiFuetLeOLzAq6Z1L9h3MFX\n9TOplhaWccqwpm3It5dVcNuLecxZX0JGUjS3njqYi8dltnhaKjE6nJEZiczJL+G2M9p+7W1lB7jt\nxTzmrt/Ft0/M4q6zhjdceJiVFsuPpw7lk7VFzCsoaTJQ35ZFm3azsWQfWWlxZKXFkhAVRlF5JRuK\n97OhZB+DesQd9vTltigUROSI6J8aQ2ZyNC8u2ExxeRX7q2r4z9Jt9E+J4a6zh7V7fyMzEgkxz3rV\njUPhg5U7uOOVJVRU13HfRTlcPC7TpyvFj8tO44lZ69uc5vrOsm3c+doyqmvruO/iHC7NPXR8ZXiv\nBBKjw5mbv8vnUNi5p4Jrn5hPeWVNw30RYSFU1Xy1FOs3j89SKIhI92BmnDWiF499VsDyLXuIiQgl\nLS6S+y8b3aFrBGIjwxjUI65hXKG2zvG/M1bx+KwCju2TwF+vGEN2O2ZITc5O5ZFP8lmwYTcnDTm0\nc8K6neX85cMv+feSrYzKTOSBy8e0ODsqJMQYPyCFuQWtXxXe2O/fXU1VTR3/+tZEyitrvD2eKslM\njqF/agxZabENDRT9SaEgIkfM3WcP5wenDyE6PLRTWmmPykziw9U72VtRzfdfyOO/q3dy3XH9ufuc\n4e2eRZQ7IJnwUGN2fkmTUFi9fQ9/++86ZizbRlRYKLeeNpjvnTqozQ6tkwam8MGqHWwrO9Dm+hgL\nN+7itUVbuHlK9mG1Ze8MCgUROWLMrN2twVszqm8SLy8s5Ny/zaJw9wF+c8EIru7gBWgxEWGM6ZvM\nnPzihvs+WrOTbz29gOjwUG46OZtpJ2S1evFdY5O8A9bz1u/igjEHN4j+Sm2d4543V9A7MYpbTg38\nbCWFgogctUZ7B5t37aviqRvGc+Lgw2uYeVx2Kn/775eUHahm974qvv/8Yob0jOf5b08kKaZ9A+7D\neyeQEBXG3PUlrYbC8/M3sWLrHv52xZgu0Woj8BWIiHTQMb0T+OV5x3L8oDQG9fB9/KAlk7NT+cuH\nX/Lxmp089FE+ISHGo9eMa3cggOfajAlZqcxd3/y4wsaSfcxaV8wf31vDpIEpnJvTseVdO5tCQUSO\nWiEhxnWTB3Ta/kb3SyIqPIQ7X11GZU0tT90woc2rq1tTP66wvayCXometa9fX1zI/e+vZfMuT0uM\nfikx/OaCEe2+INBfFAoiIl6RYaGMH5DCZ18W85Opw5qdhdQeDeMKBSWcPzqDVdv28JNXljG0Vzzf\nOm8gJwxOY2BabJcJBFAoiIg0cdPJ2Yzrn8yNJw887H0N751AvHdc4WvH9uK2F/NIiA7nqRvG+zxg\nfaQpFEREGpk8KK3TpoWGhhgTs1KYu34Xf3pvDau37+XJ63O7bCCAWmeLiPjVxKxUCor38dhnBVw1\nsR+nDusZ6JJapVAQEfGj+nGFrLRYfnrO8ABX0zadPhIR8aNj+yTwnZMHcuGYjC5xHUJbun6FIiJH\nsZAQ466zuv4RQj2dPhIRkQYKBRERaaBQEBGRBn4NBTObamZrzGydmd3ZwjaXmtlKM1thZv/yZz0i\nItI6vw00m1ko8CBwBlAIfGFmbznnVjbaZjBwF3C8c263mfVofm8iInIk+PNIYQKwzjm33jlXBbwA\nnH/QNt8GHnTO7QZwzu30Yz0iItIGf4ZCBrC50e1C732NDQGGmNnnZjbXzKb6sR4REWlDoK9TCAMG\nA1OATOBTMxvpnCttvJGZTQemA/Tr1+9I1ygiEjT8GQpbgL6Nbmd672usEJjnnKsGCsxsLZ6Q+KLx\nRs65R4FHAcysyMw2drCmNKC4za2Ciz6TpvR5HEqfSVNH6+fh0zql/gyFL4DBZpaFJwwuB648aJs3\ngCuAf5hZGp7TSetb26lzrsMNzs1sgXMut6PP7470mTSlz+NQ+kya6u6fh9/GFJxzNcAtwExgFfCS\nc26Fmf3KzM7zbjYTKDGzlcBHwB3OuebXrhMREb/z65iCc24GMOOg++5p9LMDbvf+ERGRAAu2K5of\nDXQBXZA+k6b0eRxKn0lT3frzMM8/1kVERILvSEFERFoRNKHgSx+m7szM+prZR436TH3fe3+Kmb1v\nZl96/5sc6FqPJDMLNbPFZva293aWmc3zfk9eNLOIQNd4JJlZkpm9YmarzWyVmR0XzN8RM7vN+/dl\nuZk9b2ZR3f07EhSh0KgP01nAMcAVZnZMYKs64mqAHzrnjgEmAd/1fgZ3Ah865wYDH3pvB5Pv45kd\nV+9e4M/OuUHAbmBaQKoKnL8A7zrnhgGj8Hw2QfkdMbMM4FYg1zk3AgjFM7W+W39HgiIU8K0PU7fm\nnNvmnFvk/Xkvnr/sGXg+h6e9mz0NXBCYCo88M8sEzgEe99424FTgFe8mwfZ5JAInAU8AOOeqvN0F\ngvY7gmeGZrSZhQExwDa6+XckWELBlz5MQcPMBgBjgHlAT+fcNu9D24GeASorEB4AfgzUeW+nAqXe\na2wg+L4nWUARnotJF5vZ42YWS5B+R5xzW4A/ApvwhEEZsJBu/h0JllAQLzOLA14FfuCc29P4Me91\nI0ExHc3MzgV2OucWBrqWLiQMGAs87JwbA+zjoFNFQfYdScZzlJQF9AFigW7ftDNYQsGXPkzdnpmF\n4wmE55xzr3nv3mFmvb2P9waCpX358cB5ZrYBz+nEU/GcT0/yniqA4PueFAKFzrl53tuv4AmJYP2O\nnA4UOOeKvP3ZXsPzvenW35FgCYWGPkzemQKXA28FuKYjynu+/AlglXPu/kYPvQVc5/35OuDNI11b\nIDjn7nLOZTrnBuD5PvzXOXcVnnYrF3s3C5rPA8A5tx3YbGZDvXedBqwkSL8jeE4bTTKzGO/fn/rP\no1t/R4Lm4jUzOxvPOeRQ4Enn3G8DXNIRZWYnAJ8By/jqHPrdeMYVXgL6ARuBS51zuwJSZICY2RTg\nR865c81sIJ4jhxRgMXC1c64ykPUdSWY2Gs/AewSe5pQ34PnHY1B+R8zsl8BleGbvLQa+hWcModt+\nR4ImFEREpG3BcvpIRER8oFAQEZEGCgUREWmgUBARkQYKBRERaaBQkG7JzJ7zdsVdbmZPei/cwzz+\n6u1wudTMxjZ6znXeTqBfmtl1je4fZ2bLvM/5q3fOOmZ2vZn1abTdBu9a451R/6/M7PQ2tjmvpY6/\nZlbezte7oK0mkWY2pb6brHRfCgU5qng73vriOWAYMBKIxjO/HDydcgd7/0wHHvbuNwX4BTARTwPF\nXzRqEf0w8O1Gz6tvdXA9nvYHnc45d49z7oM2tnnLOff7TnrJC/B0EJYgp1AQvzGzq81svpnlmdn/\nedcuuNHM/tBom+vN7O8tbe+9v9zM/mRmS4CfmtkbjZ5/hpm9fvBrO+dmOC9gPp52BODpZfOM96G5\neFoW9Aa+BrzvnNvlnNsNvA9M9T6W4Jyb693XM8AFZnYxkAs856032rv/75nZIu+RxbBmPpPrzewN\n77oEG8zsFjO73duAbq43nDCzp7yvUX8E8suD99v4s2vh8/+zedYC+NDM0r33fdvMvjCzJWb2qvdq\n3cnAecAfvO8l28wGmdkH3u0WmVm2d7dx9tV6C8/VHzVJ96FQEL8ws+F4rgQ93jk3GqgFrsLTe+nC\nRpteBrzQyvbgaUQ2zzk3Cvg1MKz+lxyeK26fbKWOcOAa4F3vXS11zG3t/sKD73fOvQIsAK5yzo12\nzh3wPl7snBuL5+jiRy2UNQL4BjAe+C2w39uAbg5wbQvP8WW/jcUCC5xzxwKf4DkKAnjNOTfe+1mu\nAqY552bjaWVxh/e95OM50nrQu91kPF1CwdNd9wd4jioG4ukFJN2IQkH85TRgHPCFmeV5bw90zhUB\n681skpml4jnF83lL23v3VYsnTOq7dP4TuNrMkoDjgHdaqeMh4FPn3Ged/QZbUN9ocCEwoIVtPnLO\n7fV+FmXAv733L2vlOb7st7E64EXvz88CJ3h/HmFmn5nZMjyhe+zBTzSzeDzB9zqAc67CObff+/B8\n51yhc64OyPOxFjmKhLW9iUiHGPC0c+6uZh57AbgUWA287pxz3tMQLW1f4ZyrbXT7H3h+kVYALzfq\nbd+0ALNfAOnAdxrd3VLH3C3AlIPu/9h7f2Yz27ekvgdOLS3//WrcJ6eu0e06H55zyH69p9nqW4C/\n5Zy7p5nn1/ezeQq4wDm3xMyup+l79kXj2lt7j3KU0pGC+MuHwMVm1gMa1oLu733sdTzn9q/AExBt\nbd+Ec24rsBX4GZ6AOISZfQvPOMEV3n/V1nsLuNY7C2kSUOZdQGYmcKaZJXsHmM8EZnof2+M9sjE8\np3fqu2LuBeLb97F0Pudcrfe0z+hGgRDCV508rwRmeX+OB7Z5T6td1Wg3De/FuzJfoZldAGBmkWYW\n4+/3IV2DQkH8wjm3Es8v7ffMbCmegdve3sd24zmf3d85N7+t7VvwHLDZObeqhccfwbNC2Bzv4Gn9\nL8sZeLp/rgMeA272vv4uPOMVX3j//KpRJ9Cb8XQOXQfk89XpqqeARw4aaO4q9gETzGw5nrUifuW9\n/+d4OuN+judIrd4LwB3eAe9sPOMwt3r/X8wGeh2xyiWg1CVVjkreWTeLnXNPBLoWke5EoSBHHTNb\niOdfwmd0pz72Il2BQkFERBpoTEFERBooFEREpIFCQUREGigURESkgUJBREQaKBRERKTB/wNfw3EZ\ndvW/PwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f20ed1487b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lossvsiter)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('every 2000th mini-batch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets save the model !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " torch.save(net.state_dict(),\"./models/archi2-with-reg-e5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
